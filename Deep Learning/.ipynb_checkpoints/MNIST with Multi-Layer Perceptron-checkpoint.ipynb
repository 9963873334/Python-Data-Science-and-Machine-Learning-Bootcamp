{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron\n",
    "\n",
    "In this lecture we will build out a Multi Layer Perceptron model to try to classify hand written digits using TensorFlow (a very famous example).\n",
    "\n",
    "Keep in mind that no single lecture (or course!) can cover the vastness that is Deep Learning, I would highly suggest reading MIT's [Deep Learning](http://www.deeplearningbook.org/) textbook for more information on these topics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We will be using the famous MNIST data set of [handwritten digits](http://yann.lecun.com/exdb/mnist/). \n",
    "\n",
    "The images which we will be working with are black and white images of size 28 x 28 pixels, or 784 pixels total. Our features will be the pixel values for each pixel. Either the pixel is \"white\" (blank with a 0), or there is some pixel value. \n",
    "\n",
    "We will try to correctly predict what number is written down based solely on the image data in the form of an array. This type of problem (Image Recognition) is a great use case for Deep Learning Methods!\n",
    "\n",
    "This data is to Deep Learning what the iris data set is to typical machine learning algorithms.  \n",
    "\n",
    "Let's get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format\n",
    "\n",
    "The data is stored in a vector format, although the original data was a 2-dimensional matirx with values representing how much pigment was at a certain location. Let's explore this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnist.train.images[0]\n",
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12d53ab38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD+CAYAAAD1VNNvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+A0jp5j4DSOn/H8J2ognb7APkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1216527f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "We'll need to define 4 parameters, it is really (really) hard to know what good parameter values are on a data set for which you have no experience with, however since MNIST is pretty famous, we have some reasonable values for our data below. The parameters here are:\n",
    "\n",
    "* Learning Rate - How quickly to adjust the cost function.\n",
    "* Training Epochs - How many training cycles to go through\n",
    "* Batch Size - \n",
    "* Display Step - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters\n",
    "\n",
    "Here we have parameters which will directly define our Neural Network, these would be adjusted depending on what your data looked like and what kind of a net you would want to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorFlow Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Model\n",
    "\n",
    "It is time to create our model, let's review what we want to create here.\n",
    "\n",
    "First we receive the input data array and then to send it to the first hidden layer. Then the data will begin to have a weight attached to it between layers (remember this is initially a random value) and then sent to a node to undergo an activation function (along with a Bias as mentioned in the lecture). Then it will continue on to the next hidden layer, and so on until the final output layer. In our case, we will just use two hidden layers, the more you use the longer the model will take to run (but it has more of an opportunity to possibly be more accurate on the training data).\n",
    "\n",
    "Once the transformed \"data\" has reached the output layer we need to evaluate it. Here we will use a loss function (also called a cost function) to evaluate how far off we are from the desired result. In this case, how many of the classes we got correct. \n",
    "\n",
    "Then we will apply an optimization function to minimize the cost (lower the error). This is done by adjusting weight values accordingly across the network. In out example, we will use the [Adam Optimizer](http://arxiv.org/pdf/1412.6980v8.pdf), which keep in mind, relative to other mathematical concepts, is an extremely recent development.\n",
    "\n",
    "The way cost is minimized is by tinkering with the weights, with the goal of hopefully lowering the cost. How quickly we want to lower the cost is determined by the learning rate. The lower the value for learning rate, the slower we will learn, and the more likely we'll get better results. The higher the learning rate, the quicker we will learn, giving us faster training times, but also may suffer on the results. There are diminishing returns here, you cannot just keep lowering the learning rate and always do better, of course.\n",
    "\n",
    "Now we will create our model, we'll start with 2 hidden layers, which use the [RELU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) activation function, which is a very simple rectifier function which essentially either returns x or zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 143.599913390\n",
      "Epoch: 0002 cost= 39.192623323\n",
      "Epoch: 0003 cost= 24.541503551\n",
      "Epoch: 0004 cost= 16.852074078\n",
      "Epoch: 0005 cost= 12.186272811\n",
      "Epoch: 0006 cost= 9.027372831\n",
      "Epoch: 0007 cost= 6.827114918\n",
      "Epoch: 0008 cost= 5.028998541\n",
      "Epoch: 0009 cost= 3.840985706\n",
      "Epoch: 0010 cost= 2.842095554\n",
      "Epoch: 0011 cost= 2.178799392\n",
      "Epoch: 0012 cost= 1.658163023\n",
      "Epoch: 0013 cost= 1.317603246\n",
      "Epoch: 0014 cost= 0.998914008\n",
      "Epoch: 0015 cost= 0.805103334\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\",\"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!\n",
    "\n",
    "### Extra Credit: See what happens if you try to make this model again with more layers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
